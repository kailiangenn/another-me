# Another-Me ä»£ç å®ç°ç»†èŠ‚

> **å®ç°æŒ‡å—**: æœ¬æ–‡æ¡£æä¾›ç³»ç»Ÿçš„è¯¦ç»†ä»£ç å®ç°ã€æ¥å£å®šä¹‰å’Œä½¿ç”¨ç¤ºä¾‹,é…åˆ [architecture.md](./architecture.md) ç†è§£æ¶æ„è®¾è®¡

> ğŸ“‹ **æ–‡æ¡£è¯´æ˜**: 
> - åŒ…å«å®Œæ•´çš„é¡¹ç›®ç›®å½•ç»“æ„
> - éµå¾ª**æ¨¡å—æŠ½è±¡å±‚ + åŸå­èƒ½åŠ›å±‚**çš„å››å±‚æ¶æ„è®¾è®¡
> - é‡‡ç”¨**æ‰©å¹³åŒ–ç›®å½•ç»“æ„**ï¼Œé€šè¿‡å‘½åçº¦å®šåŒºåˆ†èŒè´£
> - æä¾›å„å±‚è¯¦ç»†çš„æ¥å£å®šä¹‰å’Œä»£ç ç¤ºä¾‹
> - æ‰€æœ‰ä»£ç ç¤ºä¾‹å‡å¯ç›´æ¥å‚è€ƒä½¿ç”¨
> - å¼ºè°ƒ**è‡ªä¸‹è€Œä¸Š**çš„èƒ½åŠ›å®ç°æ–¹å¼

---

## ğŸ“š æ–‡æ¡£ç›®å½•

1. [å®Œæ•´é¡¹ç›®ç›®å½•ç»“æ„](#å®Œæ•´é¡¹ç›®ç›®å½•ç»“æ„)
   - [1.1 ç›®å½•æ¶æ„æ€»è§ˆ](#ç›®å½•æ¶æ„æ€»è§ˆ)
   - [1.2 åŸºç¡€èƒ½åŠ›å±‚ç›®å½•](#åŸºç¡€èƒ½åŠ›å±‚ç›®å½•)
   - [1.3 ç»„åˆèƒ½åŠ›å±‚ç›®å½•](#ç»„åˆèƒ½åŠ›å±‚ç›®å½•)
   - [1.4 æœåŠ¡å±‚ç›®å½•](#æœåŠ¡å±‚ç›®å½•)
2. [åŸºç¡€èƒ½åŠ›å±‚ä»£ç å®ç°](#åŸºç¡€èƒ½åŠ›å±‚ä»£ç å®ç°)
   - [2.1 LLMæ¨¡å—](#llmæ¨¡å—)
   - [2.2 Vectoræ¨¡å—](#vectoræ¨¡å—)
   - [2.3 Graphæ¨¡å—](#graphæ¨¡å—)
   - [2.4 NLPæ¨¡å—](#nlpæ¨¡å—)
   - [2.5 Fileæ¨¡å—](#fileæ¨¡å—)
   - [2.6 Algorithmæ¨¡å—](#algorithmæ¨¡å—)
3. [ç»„åˆèƒ½åŠ›å±‚ä»£ç å®ç°](#ç»„åˆèƒ½åŠ›å±‚ä»£ç å®ç°)
   - [3.1 Lifeåœºæ™¯èƒ½åŠ›](#lifeåœºæ™¯èƒ½åŠ›)
   - [3.2 Workåœºæ™¯èƒ½åŠ›](#workåœºæ™¯èƒ½åŠ›)
   - [3.3 èƒ½åŠ›å·¥å‚å®ç°](#èƒ½åŠ›å·¥å‚å®ç°)
4. [æœåŠ¡å±‚ä»£ç å®ç°](#æœåŠ¡å±‚ä»£ç å®ç°)
   - [4.1 ChatServiceå®ç°](#chatserviceå®ç°)
   - [4.2 WorkProjectServiceå®ç°](#workprojectserviceå®ç°)
   - [4.3 WorkTodoServiceå®ç°](#worktodoserviceå®ç°)
   - [4.4 WorkAdviceServiceå®ç°](#workadviceserviceå®ç°)
5. [æ•°æ®æ¨¡å‹å®šä¹‰](#æ•°æ®æ¨¡å‹å®šä¹‰)
6. [ä½¿ç”¨ç¤ºä¾‹ä¸æœ€ä½³å®è·µ](#ä½¿ç”¨ç¤ºä¾‹ä¸æœ€ä½³å®è·µ)

---

## 1. å®Œæ•´é¡¹ç›®ç›®å½•ç»“æ„

> ğŸ’¡ **æ¶æ„ç†å¿µ**: ç›®å½•ç»“æ„éµå¾ª**è‡ªä¸‹è€Œä¸Š**çš„èƒ½åŠ›æä¾›æ–¹å¼ï¼Œä»åŸå­èƒ½åŠ›å±‚å‘ä¸Šæ„å»ºæ¨¡å—æŠ½è±¡ï¼Œå†ç»„åˆæˆèƒ½åŠ›ï¼Œæœ€ç»ˆåœ¨æœåŠ¡å±‚å¯¹å¤–æä¾›å®Œæ•´åŠŸèƒ½

> ğŸ“Œ **è®¾è®¡åŸåˆ™**: 
> - **æ‰©å¹³åŒ–è®¾è®¡**: æ¯ä¸ªæ¨¡å—ç›®å½•å†…æ–‡ä»¶ç›´æ¥å­˜æ”¾ï¼Œæ— å¤šå±‚åµŒå¥—
> - **å‘½åçº¦å®š**: é€šè¿‡æ–‡ä»¶ååŒºåˆ†èŒè´£ï¼ˆ`*_caller.py`, `*_store.py`, `*_manager.py`ç­‰ï¼‰
> - **æ¨¡å—åˆ†ç¦»**: æ¯ä¸ªæ¨¡å—è‡ªåŒ…å« `models.py` ç»Ÿä¸€ç®¡ç†æ•°æ®ç±»

### 1.1 ç›®å½•æ¶æ„æ€»è§ˆ

```
another-me/
â”œâ”€â”€ ame/                          # æ ¸å¿ƒä»£ç ç›®å½•
â”‚   â”œâ”€â”€ foundation/               # â­ åŸå­èƒ½åŠ›å±‚
â”‚   â”œâ”€â”€ capability/               # ğŸ”§ ç»„åˆèƒ½åŠ›å±‚
â”‚   â”œâ”€â”€ service/                  # ğŸš€ æœåŠ¡å±‚
â”‚   â”œâ”€â”€ models/                   # ğŸ“¦ æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ requirements.txt          # ä¾èµ–æ¸…å•
â”‚   â””â”€â”€ setup.py                  # åŒ…å®‰è£…è„šæœ¬
â”œâ”€â”€ ame-tests/                    # æµ‹è¯•ä»£ç ç›®å½•
â”œâ”€â”€ ame-doc/                      # æ–‡æ¡£ç›®å½•
â””â”€â”€ README.md
```

### 1.2 åŸºç¡€èƒ½åŠ›å±‚ç›®å½•

> ğŸ›ï¸ **è®¾è®¡ç†å¿µ**: åŸºç¡€èƒ½åŠ›å±‚é‡‡ç”¨**æ¨¡å—æŠ½è±¡å±‚ + åŸå­èƒ½åŠ›å±‚**ä¸¤å±‚è®¾è®¡ï¼Œæä¾›æœ€å°ç²’åº¦çš„åŸºç¡€èƒ½åŠ›

> ğŸ“ **æ¨¡å—å†…éƒ¨ç»“æ„**: æ¯ä¸ªæ¨¡å—é‡‡ç”¨ **utils + core + components** ä¸‰å±‚ç»“æ„

**æ¨¡å—å†…éƒ¨èŒè´£åˆ’åˆ†**ï¼š
- **utils/**: é€šç”¨å·¥å…·å±‚
  - `models.py`: æ•°æ®æ¨¡å‹å®šä¹‰
  - `exceptions.py`: å¼‚å¸¸ç±»å®šä¹‰
  
- **core/**: æ ¸å¿ƒå®ç°å±‚ï¼ˆåŸå­èƒ½åŠ›å±‚ï¼‰
  - `base.py`: **æŠ½è±¡åŸºç±»**ï¼ˆå®šä¹‰æ¥å£å¥‘çº¦ï¼Œä¿è¯æ‰©å±•æ€§ï¼‰
  - ç¬¬ä¸‰æ–¹æœåŠ¡è°ƒç”¨å™¨ï¼š`*_caller.py`ï¼ˆå¦‚ `openai_caller.py`ï¼‰
  - å­˜å‚¨å®ç°ï¼š`*_store.py`ï¼ˆå¦‚ `faiss_store.py`ï¼‰
  - è§£æå™¨ï¼š`*_parser.py`ï¼ˆå¦‚ `pdf_parser.py`ï¼‰
  - åˆ†æå™¨ï¼š`*_analyzer.py`ï¼ˆå¦‚ `emotion_analyzer.py`ï¼‰
  
- **components/**: ç»„åˆç»„ä»¶å±‚ï¼ˆæ¨¡å—æŠ½è±¡å±‚ï¼‰
  - æ„å»ºå™¨ï¼š`*_builder.py`ï¼ˆå¦‚ `prompt_builder.py`ï¼‰
  - ç®¡ç†å™¨ï¼š`*_manager.py`ï¼ˆå¦‚ `history_manager.py`ï¼‰
  - æ£€ç´¢å™¨ï¼š`*_retriever.py`ï¼ˆå¦‚ `hybrid_retriever.py`ï¼‰

```
foundation/                     # åŸºç¡€èƒ½åŠ›å±‚
â”œâ”€â”€ __init__.py
â”œâ”€â”€ llm/                       # ğŸ§  LLMæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils/                 # é€šç”¨å·¥å…·
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py         # æ•°æ®æ¨¡å‹
â”‚   â”‚   â””â”€â”€ exceptions.py     # å¼‚å¸¸å®šä¹‰
â”‚   â”œâ”€â”€ core/                  # æ ¸å¿ƒå®ç°ï¼ˆåŸå­å±‚ï¼‰
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py           # æŠ½è±¡åŸºç±»ï¼šLLMCaller
â”‚   â”‚   â”œâ”€â”€ openai_caller.py  # OpenAI APIè°ƒç”¨å™¨
â”‚   â”‚   â””â”€â”€ claude_caller.py  # Claude APIè°ƒç”¨å™¨(å¯é€‰)
â”‚   â””â”€â”€ components/            # ç»„åˆç»„ä»¶ï¼ˆæ¨¡å—å±‚ï¼‰
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ prompt_builder.py # æç¤ºè¯æ„å»ºå™¨
â”‚       â””â”€â”€ history_manager.py# å†å²ç®¡ç†å™¨
â”‚
â”œâ”€â”€ embedding/                 # ğŸ”¢ Embeddingæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â””â”€â”€ exceptions.py
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py           # æŠ½è±¡åŸºç±»ï¼šEmbedding
â”‚       â””â”€â”€ simple_embedding.py # OpenAI Embedding API
â”‚
â”œâ”€â”€ vector/                    # ğŸ”¢ Vectoræ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils/                 # é€šç”¨å·¥å…·
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py         # æ•°æ®æ¨¡å‹
â”‚   â”‚   â””â”€â”€ exceptions.py     # å¼‚å¸¸å®šä¹‰
â”‚   â””â”€â”€ core/                  # æ ¸å¿ƒå®ç°ï¼ˆåŸå­å±‚ï¼‰
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py           # æŠ½è±¡åŸºç±»ï¼šVectorStore
â”‚       â””â”€â”€ faiss_store.py    # Faisså‘é‡å­˜å‚¨
â”‚
â”œâ”€â”€ graph/                     # ğŸ•¸ï¸ Graphæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils/                 # é€šç”¨å·¥å…·
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py         # å«GraphSchemaå®šä¹‰
â”‚   â”‚   â”œâ”€â”€ validators.py     # æ•°æ®éªŒè¯å™¨
â”‚   â”‚   â””â”€â”€ exceptions.py
â”‚   â””â”€â”€ core/                  # æ ¸å¿ƒå®ç°ï¼ˆåŸå­å±‚ï¼‰
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py           # æŠ½è±¡åŸºç±»ï¼šGraphStore
â”‚       â””â”€â”€ falkordb_store.py # FalkorDBå›¾å­˜å‚¨
â”‚
â”œâ”€â”€ nlp/                       # ğŸ“ NLPæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â””â”€â”€ exceptions.py
â”‚   â””â”€â”€ core/                  # æ ¸å¿ƒå®ç°ï¼ˆåŸå­å±‚ï¼‰
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py           # æŠ½è±¡åŸºç±»ï¼šEmotionAnalyzer, EntityExtractorç­‰
â”‚       â”œâ”€â”€ emotion_analyzer.py  # æƒ…ç»ªåˆ†æ(spaCy/HuggingFace)
â”‚       â”œâ”€â”€ entity_extractor.py  # å®ä½“æå–NER(spaCy)
â”‚       â”œâ”€â”€ intent_classifier.py # æ„å›¾è¯†åˆ«
â”‚       â””â”€â”€ summarizer.py        # æ–‡æœ¬æ‘˜è¦
â”‚
â”œâ”€â”€ file/                      # ğŸ“„ Fileæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â””â”€â”€ exceptions.py
â”‚   â””â”€â”€ core/                  # æ ¸å¿ƒå®ç°ï¼ˆåŸå­å±‚ï¼‰
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py           # æŠ½è±¡åŸºç±»ï¼šFileParser
â”‚       â”œâ”€â”€ pdf_parser.py     # PDFè§£æ(PyPDF2)
â”‚       â”œâ”€â”€ docx_parser.py    # Wordè§£æ(python-docx)
â”‚       â”œâ”€â”€ markdown_parser.py# Markdownè§£æ
â”‚       â”œâ”€â”€ text_parser.py    # æ–‡æœ¬è§£æ
â”‚       â””â”€â”€ ppt_parser.py     # PPTè§£æ
â”‚
â””â”€â”€ algorithm/                 # âš™ï¸ Algorithmæ¨¡å—
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ utils/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ models.py
    â””â”€â”€ core/                  # æ ¸å¿ƒå®ç°ï¼ˆåŸå­å±‚ï¼‰
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ base.py           # æŠ½è±¡åŸºç±»ï¼šSimilarityCalculatorç­‰
        â”œâ”€â”€ text_similarity.py    # æ–‡æœ¬ç›¸ä¼¼åº¦(NumPy)
        â”œâ”€â”€ time_analyzer.py      # æ—¶é—´è§£æ
        â””â”€â”€ todo_sorter.py        # æ‹“æ‰‘æ’åº(NetworkX)
```

### ç»„åˆèƒ½åŠ›å±‚ç»“æ„

### 1.3 ç»„åˆèƒ½åŠ›å±‚ç›®å½•

> ğŸ”§ **è®¾è®¡ç†å¿µ**: ç»„åˆèƒ½åŠ›å±‚åŸºäºåŸå­èƒ½åŠ›çš„ç»„åˆ,å®ŒæˆæŠ½è±¡çš„ä¸šåŠ¡æ­¥éª¤

```
capability/                    # ç»„åˆèƒ½åŠ›å±‚
â”œâ”€â”€ __init__.py
â”œâ”€â”€ common/                    # ğŸ”§ é€šç”¨ç»„åˆèƒ½åŠ›
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ hybrid_retriever.py   # æ··åˆæ£€ç´¢å™¨(Faiss 0.6 + Falkor 0.4)
â”‚
â”œâ”€â”€ life/                      # ğŸ¡ Lifeåœºæ™¯èƒ½åŠ›
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ intent_recognizer.py  # æ„å›¾è¯†åˆ«å™¨
â”‚   â”œâ”€â”€ context_retriever.py  # ä¸Šä¸‹æ–‡æ£€ç´¢å™¨
â”‚   â”œâ”€â”€ dialogue_generator.py # å¯¹è¯ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ memory_extractor.py   # è®°å¿†æå–å™¨
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ work/                      # ğŸ’¼ Workåœºæ™¯èƒ½åŠ›
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ document_parser.py    # æ–‡æ¡£è§£æå™¨
â”‚   â”œâ”€â”€ project_analyzer.py   # é¡¹ç›®åˆ†æå™¨
â”‚   â”œâ”€â”€ todo_parser.py        # å¾…åŠè§£æå™¨
â”‚   â”œâ”€â”€ todo_manager.py       # å¾…åŠç®¡ç†å™¨
â”‚   â”œâ”€â”€ pattern_analyzer.py   # æ¨¡å¼åˆ†æå™¨
â”‚   â”œâ”€â”€ advice_generator.py   # å»ºè®®ç”Ÿæˆå™¨
â”‚   â””â”€â”€ tests/
â”‚
â””â”€â”€ factory.py                 # èƒ½åŠ›å·¥å‚(ä¾èµ–æ³¨å…¥)
```

### æœåŠ¡å±‚ç»“æ„

### 1.4 æœåŠ¡å±‚ç›®å½•

> ğŸš€ **è®¾è®¡ç†å¿µ**: æœåŠ¡å±‚ç¼–æ’ç»„åˆèƒ½åŠ›,å®ç°å®Œæ•´çš„ä¸šåŠ¡æµç¨‹,ç›´æ¥å¯¹å¤–æä¾›æœåŠ¡

```
service/                       # æœåŠ¡å±‚
â”œâ”€â”€ __init__.py
â”œâ”€â”€ life/                      # ğŸ¡ ç”Ÿæ´»åœºæ™¯æœåŠ¡
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chat_service.py       # ChatService
â”‚   â””â”€â”€ tests/
â”‚
â””â”€â”€ work/                      # ğŸ’¼ å·¥ä½œåœºæ™¯æœåŠ¡
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ project_service.py    # WorkProjectService
    â”œâ”€â”€ todo_service.py       # WorkTodoService
    â”œâ”€â”€ advice_service.py     # WorkAdviceService
    â””â”€â”€ tests/
```

---

## 2. åŸºç¡€èƒ½åŠ›å±‚ä»£ç å®ç°

> ğŸ›ï¸ **èƒ½åŠ›åŸºåº§**: åŸºç¡€èƒ½åŠ›å±‚æ˜¯æ•´ä¸ªç³»ç»Ÿçš„èƒ½åŠ›åŸºåº§ï¼Œæä¾›æœ€å°ç²’åº¦çš„åŸå­æ“ä½œ

> ğŸ›ï¸ **ä¸¤å±‚æ¶æ„**: é‡‡ç”¨**æ¨¡å—æŠ½è±¡å±‚ + åŸå­èƒ½åŠ›å±‚**çš„ä¸¤å±‚è®¾è®¡
> - **æ¨¡å—æŠ½è±¡å±‚**: å®šä¹‰èƒ½åŠ›è¾¹ç•Œå’Œå¯¹å¤–æ¥å£ï¼Œå±è”½åº•å±‚å®ç°ç»†èŠ‚
> - **åŸå­èƒ½åŠ›å±‚**: æä¾›å…·ä½“çš„æŠ€æœ¯å®ç°(å¦‚OpenAIã€Faissã€spaCyç­‰)

### 2.0 base.py è®¾è®¡ç†å¿µ

> ğŸ”‘ **æ‰©å±•æ€§ä¿è¯**: æ¯ä¸ªæ¨¡å—çš„ `core/base.py` å®šä¹‰æŠ½è±¡åŸºç±»ï¼Œç¡®ä¿ç”¨æˆ·å¯ä»¥è‡ªå®šä¹‰æ‰©å±•

**è®¾è®¡åŸåˆ™**ï¼š

1. **å¼€é—­åŸåˆ™** (Open-Closed Principle)
   - å¯¹æ‰©å±•å¼€æ”¾ï¼šç”¨æˆ·å¯ä»¥ç»§æ‰¿ `base.py` ä¸­çš„æŠ½è±¡ç±»å®ç°è‡ªå·±çš„ç‰ˆæœ¬
   - å¯¹ä¿®æ”¹å…³é—­ï¼šä¸Šå±‚ä»£ç åªä¾èµ–æŠ½è±¡æ¥å£ï¼Œä¸æ„ŸçŸ¥åº•å±‚å®ç°å˜åŒ–

2. **é‡Œæ°æ›¿æ¢åŸåˆ™** (Liskov Substitution Principle)
   - æ‰€æœ‰å®ç°ç±»éƒ½å¯ä»¥é€æ˜æ›¿æ¢
   - ä¾‹ï¼š`OpenAICaller`ã€`ClaudeCaller` éƒ½å¯ä»¥æ›¿æ¢ `LLMCaller`

3. **ä¾èµ–å€’ç½®åŸåˆ™** (Dependency Inversion Principle)
   - ä¸Šå±‚æ¨¡å—ä¾èµ–æŠ½è±¡ï¼Œè€Œéå…·ä½“å®ç°
   - ä¾‹ï¼š`HybridRetriever` ä¾èµ– `VectorStore` æŠ½è±¡ï¼Œè€Œé `FaissStore`

**æ‰©å±•ç¤ºä¾‹**ï¼š

```
# ç”¨æˆ·å¯ä»¥è‡ªå®šä¹‰ LLM å®ç°
from ame.foundation.llm.core.base import LLMCaller

class CustomLLMCaller(LLMCaller):
    """[ç”¨æˆ·è‡ªå®šä¹‰] æœ¬åœ°LLMè°ƒç”¨å™¨"""
    
    def call(self, prompt: str, model: str, temperature: float, max_tokens: int) -> str:
        # è°ƒç”¨æœ¬åœ° LLaMA æ¨¡å‹
        return self.local_llama.generate(prompt)
    
    def call_stream(self, prompt: str, model: str):
        # æµå¼è¾“å‡º
        for chunk in self.local_llama.stream(prompt):
            yield chunk

# ç³»ç»Ÿè‡ªåŠ¨æ”¯æŒï¼Œæ— éœ€ä¿®æ”¹ä¸Šå±‚ä»£ç 
caller = CustomLLMCaller()
response = caller.call("Hello", "llama-7b", 0.7, 100)
```

**base.py æ ¸å¿ƒèŒè´£**ï¼š

| æ¨¡å— | base.py å®šä¹‰çš„æŠ½è±¡ç±» | è¯´æ˜ |
|------|---------------------|------|
| **LLM** | `LLMCaller` | å®šä¹‰ `call()`, `call_stream()`, `batch_call()` æ¥å£ |
| **Embedding** | `Embedding` | å®šä¹‰ `embed()`, `embed_batch()` æ¥å£ |
| **Vector** | `VectorStore` | å®šä¹‰ `add()`, `search()` æ¥å£ |
| **Graph** | `GraphStore` | å®šä¹‰ `add_node()`, `add_edge()`, `query()` æ¥å£ |
| **NLP** | `EmotionAnalyzer`, `EntityExtractor`, `IntentClassifier`, `Summarizer` | å®šä¹‰å„è‡ªNLPèƒ½åŠ›æ¥å£ |
| **File** | `FileParser` | å®šä¹‰ `parse()` ç»Ÿä¸€æ¥å£ |
| **Algorithm** | `SimilarityCalculator`, `TimeAnalyzer`, `Sorter` | å®šä¹‰ç®—æ³•ç±»æ¥å£ |

---

### 2.1 LLMæ¨¡å—

#### æ¨¡å—å®šä½

**èƒ½åŠ›è¾¹ç•Œ**: å¤§æ¨¡å‹è°ƒç”¨ã€æç¤ºè¯ç®¡ç†ã€å¯¹è¯å†å²ç®¡ç†

**æŠ€æœ¯é€‰å‹**: OpenAI API (GPT-4/GPT-3.5-turbo)

**å¯¹å¤–æ¥å£**: `call()`, `build_prompt()`, `manage_history()`

**ç›®å½•ç»“æ„** (utils + core + components):
```
llm/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ utils/                 # é€šç”¨å·¥å…·
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py         # æ•°æ®æ¨¡å‹
â”‚   â””â”€â”€ exceptions.py     # å¼‚å¸¸å®šä¹‰
â”œâ”€â”€ core/                  # æ ¸å¿ƒå®ç°ï¼ˆåŸå­å±‚ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py           # æŠ½è±¡åŸºç±»ï¼šLLMCaller(ä¿è¯æ‰©å±•æ€§)
â”‚   â”œâ”€â”€ openai_caller.py  # OpenAI APIè°ƒç”¨å™¨
â”‚   â””â”€â”€ claude_caller.py  # Claude APIè°ƒç”¨å™¨(å¯é€‰)
â””â”€â”€ components/            # ç»„åˆç»„ä»¶ï¼ˆæ¨¡å—å±‚ï¼‰
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ prompt_builder.py # æç¤ºè¯æ„å»ºå™¨
    â””â”€â”€ history_manager.py# å†å²ç®¡ç†å™¨
```

#### æ¨¡å—å±‚æ¥å£å®šä¹‰

```python
from abc import ABC, abstractmethod
from typing import Iterator, List, Dict

class LLMCaller(ABC):
    """LLMè°ƒç”¨æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def call(self, prompt: str, model: str, temperature: float, max_tokens: int) -> str:
        """
        åŒæ­¥è°ƒç”¨LLM
        - è¾“å…¥: æç¤ºè¯ã€æ¨¡å‹é…ç½®å‚æ•°
        - è¾“å‡º: ç”Ÿæˆçš„æ–‡æœ¬å“åº”
        - åŠŸèƒ½: æ”¯æŒé‡è¯•ã€ç¼“å­˜ã€æ—¥å¿—è®°å½•
        """
        pass
    
    @abstractmethod
    def call_stream(self, prompt: str, model: str) -> Iterator[str]:
        """æµå¼è°ƒç”¨LLM"""
        pass
    
    @abstractmethod
    def batch_call(self, prompts: List[str]) -> List[str]:
        """æ‰¹é‡è°ƒç”¨LLM"""
        pass

class PromptBuilder:
    """æç¤ºè¯æ„å»ºå™¨"""
    
    def build(self, template: str, context: Dict, variables: Dict) -> str:
        """æ„å»ºæç¤ºè¯"""
        pass
    
    def build_with_history(self, template: str, history: List[Dict]) -> str:
        """å¸¦å†å²çš„æç¤ºè¯æ„å»º"""
        pass
    
    def build_few_shot(self, template: str, examples: List[Dict]) -> str:
        """Few-shotæç¤ºè¯æ„å»º"""
        pass

class HistoryManager:
    """å¯¹è¯å†å²ç®¡ç†å™¨"""
    
    def manage(self, messages: List[Dict], max_length: int) -> List[Dict]:
        """ç®¡ç†å¯¹è¯å†å²"""
        pass
    
    def summarize_history(self, messages: List[Dict], llm_caller) -> str:
        """å‹ç¼©å†å²ä¸ºæ‘˜è¦"""
        pass
```

### 2.2 Vectoræ¨¡å—

#### æ¨¡å—å®šä½

**èƒ½åŠ›è¾¹ç•Œ**: å‘é‡å­˜å‚¨ä¸ç›¸ä¼¼åº¦æ£€ç´¢

**æŠ€æœ¯é€‰å‹**: Faiss

**å¯¹å¤–æ¥å£**: `add()`, `search()`

**å…³é”®ç‰¹æ€§**:
- è½»é‡é«˜æ•ˆçš„å‘é‡æ£€ç´¢ï¼Œé€‚åˆä¸­å°è§„æ¨¡åœºæ™¯
- æ”¯æŒå‘é‡+æ–‡æœ¬+å…ƒæ•°æ®ä¸€èµ·å­˜å‚¨
- é«˜æ•ˆçš„ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—

**ç›®å½•ç»“æ„** (utils + core):
```
vector/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ utils/                 # é€šç”¨å·¥å…·
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py         # æ•°æ®æ¨¡å‹
â”‚   â””â”€â”€ exceptions.py     # å¼‚å¸¸å®šä¹‰
â””â”€â”€ core/                  # æ ¸å¿ƒå®ç°ï¼ˆåŸå­å±‚ï¼‰
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ base.py           # æŠ½è±¡åŸºç±»ï¼šVectorStore(ä¿è¯æ‰©å±•æ€§)
    â””â”€â”€ faiss_store.py    # Faisså‘é‡å­˜å‚¨
```

#### æ¨¡å—å±‚æ¥å£å®šä¹‰

```python
from abc import ABC, abstractmethod
from typing import List, Dict

class VectorStore(ABC):
    """å‘é‡å­˜å‚¨æŠ½è±¡æ¥å£"""
    
    @abstractmethod
    def add(self, id: str, vector: List[float], metadata: Dict) -> bool:
        """
        æ·»åŠ å‘é‡
        - è¾“å…¥: IDã€å‘é‡ã€å…ƒæ•°æ®
        - è¾“å‡º: æ·»åŠ æˆåŠŸä¸å¦
        - åŠŸèƒ½: æ”¯æŒå‘é‡+æ–‡æœ¬+å…ƒæ•°æ®ä¸€èµ·å­˜å‚¨
        """
        pass
    
    @abstractmethod
    def search(self, query_vector: List[float], top_k: int, filter: Dict = None) -> List[Dict]:
        """
        ç›¸ä¼¼åº¦æ£€ç´¢
        - è¾“å…¥: æŸ¥è¯¢å‘é‡ã€è¿”å›æ•°é‡ã€è¿‡æ»¤æ¡ä»¶
        - è¾“å‡º: ç›¸ä¼¼ç»“æœåˆ—è¡¨
        - åŠŸèƒ½: åŸºäºä½™å¼¦ç›¸ä¼¼åº¦æ£€ç´¢
        """
        pass
    
    @abstractmethod
    def delete(self, id: str) -> bool:
        """åˆ é™¤å‘é‡"""
        pass
    
    @abstractmethod
    def update(self, id: str, vector: List[float], metadata: Dict) -> bool:
        """æ›´æ–°å‘é‡"""
        pass

---

### 2.3 Graphæ¨¡å—

#### æ¨¡å—å®šä½

**èƒ½åŠ›è¾¹ç•Œ**: å›¾è°±å­˜å‚¨ã€å›¾æŸ¥è¯¢ã€å…³ç³»æ¼”åŒ–åˆ†æ

**æŠ€æœ¯é€‰å‹**: FalkorDB

**å¯¹å¤–æ¥å£**: `add_node()`, `add_edge()`, `query()`

**å…³é”®ç‰¹æ€§**:
- å›¾è¾¹æ”¯æŒæ—¶é—´å±æ€§: `create_time`(ç”Ÿæ•ˆæ—¶é—´) / `invalid_time`(å¤±æ•ˆæ—¶é—´)
- æ”¯æŒå…³ç³»æ¼”åŒ–åˆ†æï¼Œè·Ÿè¸ªå…³ç³»å˜åŒ–
- ä¸Redisç”Ÿæ€é›†æˆï¼Œé«˜æ€§èƒ½å›¾è®¡ç®—

**ç›®å½•ç»“æ„** (utils + core):
```
graph/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ utils/                 # é€šç”¨å·¥å…·
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py         # å«GraphSchemaå®šä¹‰
â”‚   â”œâ”€â”€ validators.py     # æ•°æ®éªŒè¯å™¨
â”‚   â””â”€â”€ exceptions.py
â””â”€â”€ core/                  # æ ¸å¿ƒå®ç°ï¼ˆåŸå­å±‚ï¼‰
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ base.py           # æŠ½è±¡åŸºç±»ï¼šGraphStore(ä¿è¯æ‰©å±•æ€§)
    â””â”€â”€ falkordb_store.py # FalkorDBå›¾å­˜å‚¨
```

#### æ¨¡å—å±‚æ¥å£å®šä¹‰

```python
from abc import ABC, abstractmethod
from typing import List, Dict

class GraphStore(ABC):
    """å›¾å­˜å‚¨æŠ½è±¡æ¥å£"""
    
    @abstractmethod
    def add_node(self, node_type: str, properties: Dict) -> str:
        """
        æ·»åŠ èŠ‚ç‚¹
        - è¾“å…¥: èŠ‚ç‚¹ç±»å‹ã€å±æ€§å­—å…¸
        - è¾“å‡º: èŠ‚ç‚¹ID
        """
        pass
    
    @abstractmethod
    def add_edge(self, from_id: str, to_id: str, edge_type: str, properties: Dict) -> str:
        """
        æ·»åŠ è¾¹(æ”¯æŒæ—¶é—´å±æ€§)
        - è¾“å…¥: èµ·ç‚¹IDã€ç»ˆç‚¹IDã€è¾¹ç±»å‹ã€å±æ€§å­—å…¸
        - è¾“å‡º: è¾¹ID
        - propertiesåº”åŒ…å«: create_time, invalid_time
        """
        pass
    
    @abstractmethod
    def query(self, cypher: str, params: Dict = None) -> List[Dict]:
        """
        CypheræŸ¥è¯¢
        - è¾“å…¥: CypheræŸ¥è¯¢è¯­å¥ã€å‚æ•°
        - è¾“å‡º: æŸ¥è¯¢ç»“æœåˆ—è¡¨
        """
        pass
    
    @abstractmethod
    def update_edge(self, edge_id: str, properties: Dict) -> bool:
        """
        æ›´æ–°è¾¹(ç”¨äºè®¾ç½®invalid_time)
        - è¾“å…¥: è¾¹IDã€æ›´æ–°å±æ€§
        - è¾“å‡º: æ›´æ–°æˆåŠŸä¸å¦
        """
        pass
    
    @abstractmethod
    def delete_node(self, node_id: str) -> bool:
        """åˆ é™¤èŠ‚ç‚¹"""
        pass
    
    @abstractmethod
    def delete_edge(self, edge_id: str) -> bool:
        """åˆ é™¤è¾¹"""
        pass
```

#### GraphSchemaå®šä¹‰

**è®¾è®¡ç†å¿µ**: å®šä¹‰æ ‡å‡†çš„å›¾è°±ç»“æ„,æ”¯æŒæ—¶é—´ç»´åº¦çš„å…³ç³»æ¼”åŒ–åˆ†æ

```python
class GraphSchema:
    """å›¾è°±Schemaå®šä¹‰"""
    
    NODE_TYPES = {
        'User': ['user_id', 'name', 'created_at'],
        'Memory': ['content', 'emotion', 'timestamp'],
        'Entity': ['name', 'type', 'description'],  # NERæå–
        'Document': ['title', 'content', 'type', 'created_at'],
        'Todo': ['title', 'priority', 'status', 'deadline'],
        'Session': ['session_id', 'start_time', 'end_time']
    }
    
    EDGE_TYPES = {
        'MENTIONS': {  # (Document/Memory)-[:MENTIONS]->(Entity)
            'properties': ['create_time', 'invalid_time']
        },
        'LIKES': {  # (User)-[:LIKES]->(Entity)
            'properties': ['create_time', 'invalid_time', 'intensity']
        },
        'DEPENDS_ON': {  # (Todo)-[:DEPENDS_ON]->(Todo)
            'properties': ['create_time', 'invalid_time']
        }
    }
```

---

## 3. ç»„åˆèƒ½åŠ›å±‚ä»£ç å®ç°

> ğŸ”§ **èƒ½åŠ›ç»„åˆ**: ç»„åˆèƒ½åŠ›å±‚å°†å¤šä¸ªåŸå­èƒ½åŠ›ç»„åˆèµ·æ¥,å®ŒæˆæŠ½è±¡çš„ä¸šåŠ¡æ­¥éª¤

> ğŸ¯ **ç¼–æ’ç†å¿µ**: æœåŠ¡å±‚é€šè¿‡ç¼–æ’è¿™äº›ç»„åˆèƒ½åŠ›å®ç°å®Œæ•´çš„ä¸šåŠ¡æµç¨‹

### 3.0 é€šç”¨ç»„åˆèƒ½åŠ›

#### HybridRetriever - æ··åˆæ£€ç´¢å™¨

**è®¾è®¡ç†å¿µ**: å°† Vector æ¨¡å—çš„å‘é‡æ£€ç´¢ä¸ Graph æ¨¡å—çš„å›¾æŸ¥è¯¢èåˆï¼Œæä¾›æ›´å…¨é¢çš„æ£€ç´¢èƒ½åŠ›

**æ ¸å¿ƒåŠŸèƒ½**:
- å¹¶è¡Œè°ƒç”¨å‘é‡æ£€ç´¢ï¼ˆFaissï¼‰å’Œå›¾è°±æ£€ç´¢ï¼ˆFalkorDBï¼‰
- åŠ æƒèåˆç­–ç•¥: Faiss 0.6 + Falkor 0.4
- æ”¯æŒè¯­ä¹‰ç›¸ä¼¼åº¦ + å…³ç³»æ¨ç†

```python
from typing import List, Dict
from ame.foundation.vector.core.base import VectorStore
from ame.foundation.graph.core.base import GraphStore

class HybridRetriever:
    """æ··åˆæ£€ç´¢å™¨ - Faiss 0.6 + Falkor 0.4"""
    
    def __init__(self, 
                 vector_store: VectorStore, 
                 graph_store: GraphStore, 
                 vector_weight: float = 0.6, 
                 graph_weight: float = 0.4):
        """
        åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨
        
        Args:
            vector_store: å‘é‡å­˜å‚¨å®ä¾‹
            graph_store: å›¾å­˜å‚¨å®ä¾‹
            vector_weight: å‘é‡æ£€ç´¢æƒé‡ï¼ˆé»˜è®¤0.6ï¼‰
            graph_weight: å›¾æŸ¥è¯¢æƒé‡ï¼ˆé»˜è®¤0.4ï¼‰
        """
        self.vector_store = vector_store
        self.graph_store = graph_store
        self.vector_weight = vector_weight
        self.graph_weight = graph_weight
    
    def retrieve(self, query: str, query_vector: List[float], top_k: int = 5) -> List[Dict]:
        """
        æ··åˆæ£€ç´¢
        
        æµç¨‹:
        1. å¹¶è¡Œè°ƒç”¨å‘é‡æ£€ç´¢å’Œå›¾è°±æ£€ç´¢
        2. åŠ æƒèåˆåˆ†æ•°
        3. æ’åºè¿”å›top_kç»“æœ
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            query_vector: æŸ¥è¯¢å‘é‡
            top_k: è¿”å›ç»“æœæ•°é‡
        
        Returns:
            èåˆåçš„æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        # 1. å¹¶è¡Œè°ƒç”¨å‘é‡æ£€ç´¢å’Œå›¾è°±æ£€ç´¢
        vector_results = self.vector_store.search(query_vector, top_k * 2)
        graph_results = self._graph_search(query, top_k * 2)
        
        # 2. åŠ æƒèåˆ
        fused = self._fuse_scores(vector_results, graph_results)
        
        # 3. æ’åºè¿”å›
        return sorted(fused, key=lambda x: x['score'], reverse=True)[:top_k]
    
    def _graph_search(self, query: str, top_k: int) -> List[Dict]:
        """å›¾è°±æ£€ç´¢"""
        # æ ¹æ®æŸ¥è¯¢æ„å»ºCypherè¯­å¥
        cypher = """
        MATCH (m:Memory)-[:MENTIONS]->(e:Entity)
        WHERE e.name CONTAINS $query
        RETURN m, e, score
        ORDER BY score DESC
        LIMIT $top_k
        """
        return self.graph_store.query(cypher, {'query': query, 'top_k': top_k})
    
    def _fuse_scores(self, vector_results: List[Dict], graph_results: List[Dict]) -> List[Dict]:
        """åŠ æƒèåˆåˆ†æ•°"""
        # åˆå¹¶ç»“æœï¼ŒæŒ‰IDå»é‡
        merged = {}
        
        # å¤„ç†å‘é‡ç»“æœ
        for item in vector_results:
            item_id = item['id']
            merged[item_id] = {
                'id': item_id,
                'content': item['content'],
                'score': item['score'] * self.vector_weight,
                'source': 'vector'
            }
        
        # å¤„ç†å›¾ç»“æœ
        for item in graph_results:
            item_id = item['id']
            if item_id in merged:
                # å·²å­˜åœ¨ï¼Œèåˆåˆ†æ•°
                merged[item_id]['score'] += item['score'] * self.graph_weight
                merged[item_id]['source'] = 'hybrid'
            else:
                # æ–°å¢
                merged[item_id] = {
                    'id': item_id,
                    'content': item['content'],
                    'score': item['score'] * self.graph_weight,
                    'source': 'graph'
                }
        
        return list(merged.values())
```

---

### 3.1 Lifeåœºæ™¯èƒ½åŠ›

```python
class IntentRecognizer:
    """æ„å›¾è¯†åˆ«å™¨"""
    def recognize(self, message: str, context: Dict = None) -> Dict:
        # 1. è°ƒç”¨LLMåˆ†ææ„å›¾
        # 2. ä½¿ç”¨åˆ†ç±»å™¨å½’ç±»
        # 3. è¿”å›æ„å›¾å¯¹è±¡
        pass

class ContextRetriever:
    """ä¸Šä¸‹æ–‡æ£€ç´¢å™¨"""
    def retrieve(self, query: str, query_vector: List[float], session_id: str, top_k: int = 5):
        # ä½¿ç”¨æ··åˆæ£€ç´¢(Faiss 0.6 + Falkor 0.4)
        results = self.retriever.retrieve(query, query_vector, top_k)
        return results

class DialogueGenerator:
    """å¯¹è¯ç”Ÿæˆå™¨"""
    def generate(self, context: List[Dict], message: str) -> str:
        # 1. åˆ†æç”¨æˆ·é£æ ¼
        # 2. æ„å»ºä¸ªæ€§åŒ–æç¤ºè¯
        # 3. è°ƒç”¨LLMç”Ÿæˆå›å¤
        pass

class MemoryExtractor:
    """è®°å¿†æå–å™¨"""
    def extract(self, conversation: List[Dict]) -> List[Dict]:
        # 1. è°ƒç”¨LLMæå–è®°å¿†ç‚¹
        # 2. æƒ…ç»ªåˆ†æ
        # 3. å®ä½“æå–(NER)
        # 4. æ—¶é—´è§£æ
        pass
```

### 3.2 Workåœºæ™¯èƒ½åŠ›

```python
class TodoParser:
    """å¾…åŠè§£æå™¨"""
    def parse(self, description: str) -> List[Dict]:
        # 1. è°ƒç”¨LLMè§£æä»»åŠ¡
        # 2. æå–æ—¶é—´ä¿¡æ¯(create_time/deadline)
        # 3. æå–ä¼˜å…ˆçº§
        pass

class TodoManager:
    """å¾…åŠç®¡ç†å™¨"""
    def manage(self, new_todos: List[Dict], user_id: str) -> List[Dict]:
        # 1. æŸ¥è¯¢å·²æœ‰å¾…åŠ
        # 2. å»é‡åˆå¹¶
        # 3. æ‹“æ‰‘æ’åº
        # 4. å­˜å…¥å›¾è°±
        pass
```

### 3.3 èƒ½åŠ›å·¥å‚å®ç°

**è®¾è®¡æ¨¡å¼**: ä¾èµ–æ³¨å…¥ + å·¥å‚æ¨¡å¼

**æ ¸å¿ƒä»·å€¼**:
- ğŸ”Œ ç»Ÿä¸€ä¾èµ–ç®¡ç†: æœåŠ¡å±‚æ— éœ€å…³å¿ƒèƒ½åŠ›å®ä¾‹åˆ›å»ºç»†èŠ‚
- ğŸ”„ ä¾èµ–æ³¨å…¥: è‡ªåŠ¨å¤„ç†èƒ½åŠ›ä¹‹é—´çš„ä¾èµ–å…³ç³»
- ğŸ§ª å¯æµ‹è¯•æ€§: æ”¯æŒMockæ›¿æ¢,ä¾¿äºå•å…ƒæµ‹è¯•

```python
class CapabilityFactory:
    """èƒ½åŠ›å·¥å‚ - ç»Ÿä¸€ç®¡ç†ç»„åˆèƒ½åŠ›çš„åˆ›å»ºå’Œä¾èµ–æ³¨å…¥"""
    
    _instances = {}
    
    @classmethod
    def get_intent_recognizer(cls) -> 'IntentRecognizer':
        """è·å–æ„å›¾è¯†åˆ«å™¨"""
        if 'intent_recognizer' not in cls._instances:
            llm_caller = cls._get_llm_caller()
            intent_classifier = cls._get_intent_classifier()
            cls._instances['intent_recognizer'] = IntentRecognizer(llm_caller, intent_classifier)
        return cls._instances['intent_recognizer']
    
    @classmethod
    def get_context_retriever(cls) -> 'ContextRetriever':
        """è·å–ä¸Šä¸‹æ–‡æ£€ç´¢å™¨"""
        if 'context_retriever' not in cls._instances:
            vector_store = cls._get_vector_store()
            graph_store = cls._get_graph_store()
            hybrid_retriever = cls._get_hybrid_retriever(vector_store, graph_store)
            cls._instances['context_retriever'] = ContextRetriever(hybrid_retriever)
        return cls._instances['context_retriever']
    
    # ... å…¶ä»–èƒ½åŠ›è·å–æ–¹æ³• ...
    
    @classmethod
    def _get_hybrid_retriever(cls, vector_store, graph_store):
        """è·å–æ··åˆæ£€ç´¢å™¨(æƒé‡: Faiss 0.6 + Falkor 0.4)"""
        return HybridRetriever(vector_store, graph_store, vector_weight=0.6, graph_weight=0.4)
```

---

## 4. æœåŠ¡å±‚ä»£ç å®ç°

> ğŸš€ **ä¸šåŠ¡ç¼–æ’**: æœåŠ¡å±‚ç¼–æ’ç»„åˆèƒ½åŠ›,å®ç°å®Œæ•´çš„ä¸šåŠ¡æµç¨‹,ç›´æ¥å¯¹å¤–æä¾›æœåŠ¡

> ğŸ‘¥ **ç”¨æˆ·è§†è§’**: ç”¨æˆ·åªéœ€è°ƒç”¨Serviceå±‚æ¥å£,åº•å±‚Capabilityå’ŒFoundationç”±ç³»ç»Ÿè‡ªåŠ¨ç¼–æ’æ‰§è¡Œ

### 4.1 ChatServiceå®ç°

**æœåŠ¡èŒè´£**: æä¾›ä¸ªæ€§åŒ–å¯¹è¯èƒ½åŠ›,æ¨¡ä»¿ç”¨æˆ·é£æ ¼,ç®¡ç†å¯¹è¯è®°å¿†

**èƒ½åŠ›ç¼–æ’**: IntentRecognizer + ContextRetriever + DialogueGenerator + MemoryExtractor

```python
class ChatService:
    """ç”Ÿæ´»å¯¹è¯æœåŠ¡"""
    
    def __init__(self):
        self.intent_recognizer = CapabilityFactory.get_intent_recognizer()
        self.context_retriever = CapabilityFactory.get_context_retriever()
        self.dialogue_generator = CapabilityFactory.get_dialogue_generator()
        self.memory_extractor = CapabilityFactory.get_memory_extractor()
    
    def chat(self, message: str, session_id: str) -> str:
        """å¯¹è¯æ¥å£"""
        # 1. æ„å›¾è¯†åˆ«
        intent = self.intent_recognizer.recognize(message)
        
        # 2. ä¸Šä¸‹æ–‡æ£€ç´¢(æ··åˆæ£€ç´¢0.6+0.4)
        context = self.context_retriever.retrieve(message, session_id)
        
        # 3. å¯¹è¯ç”Ÿæˆ
        response = self.dialogue_generator.generate(context, message)
        
        return response
    
    def end_session(self, session_id: str):
        """ç»“æŸä¼šè¯,æå–è®°å¿†"""
        conversation = self._get_conversation(session_id)
        memories = self.memory_extractor.extract(conversation)
        self._save_to_graph(memories)
```

### 4.2 WorkProjectServiceå®ç°

**æœåŠ¡èŒè´£**: åˆ†æé¡¹ç›®æ–‡æ¡£,æå–æ ¸å¿ƒè¦ç´ ,ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Š

**èƒ½åŠ›ç¼–æ’**: DocumentParser + ProjectAnalyzer

```python
class WorkProjectService:
    """é¡¹ç›®åˆ†ææœåŠ¡"""
    
    def __init__(self):
        self.document_parser = CapabilityFactory.get_document_parser()
        self.project_analyzer = CapabilityFactory.get_project_analyzer()
    
    def analyze_project(self, files: List[str]) -> str:
        """
        åˆ†æé¡¹ç›®æ–‡æ¡£
        
        æµç¨‹:
        1. æ–‡æ¡£è§£æ: æ”¯æŒPDF/Word/MD/PPT
        2. å®ä½“æå–: NERæå–æ ¸å¿ƒå®ä½“
        3. å›¾è°±æ„å»º: (Document)-[:MENTIONS]->(Entity)
        4. æŠ¥å‘Šç”Ÿæˆ: LLMç”ŸæˆMarkdownæŠ¥å‘Š
        """
        # 1. æ–‡æ¡£è§£æ
        documents = self.document_parser.parse(files)
        
        # 2-4. é¡¹ç›®åˆ†æ
        report = self.project_analyzer.analyze(documents)
        
        return report
```

### 4.3 WorkTodoServiceå®ç°

**æœåŠ¡èŒè´£**: æ™ºèƒ½è§£æä»»åŠ¡,å»é‡åˆå¹¶,æ‹“æ‰‘æ’åº,æŒä¹…åŒ–ç®¡ç†

**èƒ½åŠ›ç¼–æ’**: TodoParser + TodoManager

```python
class WorkTodoService:
    """å¾…åŠç®¡ç†æœåŠ¡"""
    
    def add_todos(self, description: str, user_id: str) -> List[Dict]:
        # 1. ä»»åŠ¡è§£æ
        todos = self.todo_parser.parse(description)
        
        # 2-5. ç®¡ç†å¾…åŠ(å»é‡/æ’åº/å­˜å‚¨)
        sorted_todos = self.todo_manager.manage(todos, user_id)
        
        return sorted_todos
```

### 4.4 WorkAdviceServiceå®ç°

**æœåŠ¡èŒè´£**: åˆ†æå·¥ä½œæ¨¡å¼,ç”Ÿæˆä¸ªæ€§åŒ–æ”¹è¿›å»ºè®®

**èƒ½åŠ›ç¼–æ’**: PatternAnalyzer + AdviceGenerator

```python
class WorkAdviceService:
    """å·¥ä½œå»ºè®®æœåŠ¡"""
    
    def __init__(self):
        self.pattern_analyzer = CapabilityFactory.get_pattern_analyzer()
        self.advice_generator = CapabilityFactory.get_advice_generator()
    
    def generate_advice(self, user_id: str) -> str:
        """
        ç”Ÿæˆå·¥ä½œå»ºè®®
        
        æµç¨‹:
        1. æ•°æ®æ”¶é›†: ä»å›¾è°±æŸ¥è¯¢å·¥ä½œæ•°æ®
        2. æ¨¡å¼åˆ†æ: è®¡ç®—å®Œæˆç‡ã€å»¶æœŸç‡ã€æ•ˆç‡åˆ†æ•°
        3. å»ºè®®ç”Ÿæˆ: LLMç”Ÿæˆä¸ªæ€§åŒ–å»ºè®®
        4. Markdownæ ¼å¼åŒ–
        """
        # 1-2. åˆ†æå·¥ä½œæ¨¡å¼
        pattern = self.pattern_analyzer.analyze(user_id)
        
        # 3-4. ç”Ÿæˆå»ºè®®
        advice = self.advice_generator.generate(pattern)
        
        return advice
```

---

## 5. æ•°æ®æ¨¡å‹å®šä¹‰

### 5.1 Lifeåœºæ™¯æ•°æ®æ¨¡å‹

```python
from dataclasses import dataclass
from typing import List, Dict, Optional
from datetime import datetime

@dataclass
class Message:
    """æ¶ˆæ¯å¯¹è±¡"""
    role: str  # 'user' or 'assistant'
    content: str
    timestamp: datetime
    session_id: str

@dataclass
class Intent:
    """æ„å›¾å¯¹è±¡"""
    intent_type: str  # 'chat', 'query', 'command'
    sub_intent: Optional[str]
    confidence: float

@dataclass
class Memory:
    """è®°å¿†å¯¹è±¡"""
    content: str
    emotion: str
    emotion_intensity: float
    entities: List[Dict]  # [{entity: str, type: str}]
    timestamp: datetime
    session_id: str
    create_time: str  # ç”Ÿæ•ˆæ—¶é—´
    invalid_time: Optional[str]  # å¤±æ•ˆæ—¶é—´

@dataclass
class Context:
    """ä¸Šä¸‹æ–‡å¯¹è±¡"""
    messages: List[Message]
    memories: List[Memory]
    score: float  # ç›¸å…³æ€§åˆ†æ•°
```

### 5.2 Workåœºæ™¯æ•°æ®æ¨¡å‹

```python
@dataclass
class Document:
    """æ–‡æ¡£å¯¹è±¡"""
    title: str
    content: str
    file_type: str  # 'pdf', 'docx', 'md', 'ppt'
    metadata: Dict
    created_at: datetime

@dataclass
class Todo:
    """å¾…åŠå¯¹è±¡"""
    title: str
    description: str
    priority: int  # 1-5
    status: str  # 'pending', 'in_progress', 'done'
    create_time: datetime
    deadline: Optional[datetime]
    dependencies: List[str]  # ä¾èµ–çš„å…¶ä»–å¾…åŠID
    invalid_time: Optional[datetime]  # å¤±æ•ˆæ—¶é—´

@dataclass
class ProjectReport:
    """é¡¹ç›®æŠ¥å‘Šå¯¹è±¡"""
    title: str
    summary: str
    entities: List[Dict]
    structure: Dict
    markdown_content: str

@dataclass
class WorkPattern:
    """å·¥ä½œæ¨¡å¼å¯¹è±¡"""
    completion_rate: float  # å®Œæˆç‡
    delay_rate: float  # å»¶æœŸç‡
    efficiency_score: float  # æ•ˆç‡åˆ†æ•°
    peak_hours: List[int]  # é«˜æ•ˆæ—¶é—´æ®µ
    common_patterns: List[str]  # å¸¸è§æ¨¡å¼
```

---

## 6. ä½¿ç”¨ç¤ºä¾‹ä¸æœ€ä½³å®è·µ

### 6.1 æ—¶é—´å±æ€§ä½¿ç”¨ç¤ºä¾‹

### 6.1 æ—¶é—´å±æ€§ä½¿ç”¨ç¤ºä¾‹

**è®¾è®¡ç†å¿µ**: é€šè¿‡`create_time`å’Œ`invalid_time`å®ç°å…³ç³»çš„æ—¶é—´ç»´åº¦ç®¡ç†,æ”¯æŒå…³ç³»æ¼”åŒ–åˆ†æ

#### æ·»åŠ å¸¦æ—¶é—´çš„è¾¹

```python
# ç”¨æˆ·å¼€å§‹å–œæ¬¢æŸå®ä½“
graph_store.add_edge(
    user_id, entity_id, 'LIKES',
    {
        'create_time': '2024-01-01',
        'invalid_time': None,  # å½“å‰æœ‰æ•ˆ
        'intensity': 0.8
    }
)

# ç”¨æˆ·ä¸å†å–œæ¬¢è¯¥å®ä½“
graph_store.update_edge(edge_id, {'invalid_time': '2024-12-31'})
```

#### CypheræŸ¥è¯¢ç¤ºä¾‹

``cypher
# æŸ¥è¯¢å½“å‰ä»æœ‰æ•ˆçš„å–œå¥½
MATCH (u:User)-[r:LIKES]->(e:Entity)
WHERE r.invalid_time IS NULL
RETURN e

# æŸ¥è¯¢æŒ‡å®šæ—¶é—´èŒƒå›´çš„å…³ç³»
MATCH (u:User)-[r:LIKES]->(e:Entity)
WHERE r.create_time <= '2024-06-30' 
  AND (r.invalid_time IS NULL OR r.invalid_time > '2024-06-30')
RETURN e, r
```

---

### 6.2 æ··åˆæ£€ç´¢ä½¿ç”¨ç¤ºä¾‹

**è®¾è®¡ç†å¿µ**: å¹¶è¡Œè°ƒç”¨Vectoræ¨¡å—(è¯­ä¹‰)å’ŒGraphæ¨¡å—(å…³ç³»),åŠ æƒèåˆ(0.6+0.4)

```python
# ä½¿ç”¨æ··åˆæ£€ç´¢
from ame.capability.common import HybridRetriever
from ame.foundation.vector.core import FaissStore
from ame.foundation.graph.core import FalkorDBStore

# åˆå§‹åŒ–
v ector_store = FaissStore()
graph_store = FalkorDBStore()
hybrid_retriever = HybridRetriever(vector_store, graph_store)

# æ£€ç´¢
results = hybrid_retriever.retrieve(
    query="æˆ‘ä¸Šæ¬¡å’Œå¼ ä¸‰è®¨è®ºçš„é¡¹ç›®æ˜¯ä»€ä¹ˆ?",
    query_vector=embedding,  # ç”±Embeddingæ¨¡å—ç”Ÿæˆ
    top_k=5
)

# è¿”å›ç»“æœåŒ…å«èåˆåçš„ç›¸å…³æ€§åˆ†æ•°
for result in results:
    print(f"å†…å®¹: {result['content']}")
    print(f"åˆ†æ•°: {result['score']}")
    print(f"æ¥æº: {result['source']}")  # 'vector', 'graph', or 'hybrid'
```

### 6.3 æœåŠ¡å±‚è°ƒç”¨ç¤ºä¾‹

#### ChatServiceä½¿ç”¨ç¤ºä¾‹

```python
from service.life import ChatService

# åˆå§‹åŒ–æœåŠ¡
chat_service = ChatService()

# å‘èµ·å¯¹è¯
response = chat_service.chat(
    message="ä»Šå¤©å¿ƒæƒ…ä¸å¥½,æƒ³æ‰¾äººèŠèŠ",
    session_id="session_123"
)

print(response)  # ä¸ªæ€§åŒ–å›å¤

# ç»“æŸä¼šè¯,æå–è®°å¿†
chat_service.end_session("session_123")
```

#### WorkTodoServiceä½¿ç”¨ç¤ºä¾‹

```python
from service.work import WorkTodoService

todo_service = WorkTodoService()

# æ·»åŠ å¾…åŠ
todos = todo_service.add_todos(
    description="""
    æœ¬å‘¨éœ€è¦å®Œæˆ:
    1. å®Œæˆé¡¹ç›®è®¾è®¡æ–‡æ¡£(ä¼˜å…ˆçº§é«˜,å‘¨ä¸‰å‰)
    2. å†™å•å…ƒæµ‹è¯•(ä¾èµ–è®¾è®¡æ–‡æ¡£)
    3. Code Review
    """,
    user_id="user_123"
)

# è¿”å›æ’åºåçš„å¾…åŠåˆ—è¡¨
for todo in todos:
    print(f"{todo.title} - ä¼˜å…ˆçº§: {todo.priority}")
```

#### WorkAdviceServiceä½¿ç”¨ç¤ºä¾‹

```python
from service.work import WorkAdviceService

advice_service = WorkAdviceService()

# ç”Ÿæˆå·¥ä½œå»ºè®®
advice = advice_service.generate_advice(user_id="user_123")

print(advice)  # Markdownæ ¼å¼çš„å»ºè®®
```

### 6.4 æœ€ä½³å®è·µ

#### 1. æœåŠ¡å±‚è°ƒç”¨åŸåˆ™

**âœ… æ­£ç¡®åšæ³•**:
```python
# ç”¨æˆ·åªéœ€è°ƒç”¨Serviceå±‚
from service.life import ChatService

chat_service = ChatService()
response = chat_service.chat(message, session_id)
```

**âŒ é”™è¯¯åšæ³•**:
```python
# ä¸è¦ç›´æ¥è°ƒç”¨Capabilityæˆ–Foundationå±‚
from capability.life import IntentRecognizer  # é”™è¯¯!
from foundation.llm import OpenAICaller  # é”™è¯¯!
```

#### 2. èƒ½åŠ›å·¥å‚ä½¿ç”¨

**âœ… æ­£ç¡®åšæ³•**:
```python
# é€šè¿‡CapabilityFactoryè·å–èƒ½åŠ›
from capability import CapabilityFactory

retriever = CapabilityFactory.get_context_retriever()
```

**âŒ é”™è¯¯åšæ³•**:
```python
# ä¸è¦ç›´æ¥å®ä¾‹åŒ–èƒ½åŠ›ç±»
retriever = ContextRetriever(...)  # é”™è¯¯!
```

#### 3. æ—¶é—´å±æ€§ç®¡ç†

**âœ… æ­£ç¡®åšæ³•**:
```python
# æ·»åŠ å…³ç³»æ—¶æ€»æ˜¯è®¾ç½®create_time
graph_store.add_edge(
    user_id, entity_id, 'LIKES',
    {
        'create_time': datetime.now().isoformat(),
        'invalid_time': None,  # å½“å‰æœ‰æ•ˆ
        'intensity': 0.8
    }
)

# å¤±æ•ˆæ—¶æ›´æ–°invalid_time
graph_store.update_edge(edge_id, {
    'invalid_time': datetime.now().isoformat()
})
```

**âŒ é”™è¯¯åšæ³•**:
```python
# ä¸è¦åˆ é™¤å…³ç³»,åº”è¯¥è®¾ç½®invalid_time
graph_store.delete_edge(edge_id)  # é”™è¯¯!
```

#### 4. æ··åˆæ£€ç´¢é…ç½®

**âœ… æ­£ç¡®åšæ³•**:
```python
# ä½¿ç”¨é»˜è®¤æƒé‡(Vector 0.6 + Graph 0.4)
from ame.capability.common import HybridRetriever

retriever = HybridRetriever(vector_store, graph_store)

# æˆ–æ ¹æ®åœºæ™¯è°ƒæ•´æƒé‡
retriever = HybridRetriever(
    vector_store, graph_store,
    vector_weight=0.7,  # æ›´ä¾§é‡è¯­ä¹‰ç›¸ä¼¼åº¦
    graph_weight=0.3
)
```

#### 5. é”™è¯¯å¤„ç†

```python
from foundation.llm.utils.exceptions import LLMError
from foundation.vector.utils.exceptions import VectorStoreError  
from foundation.graph.utils.exceptions import GraphStoreError

try:
    response = chat_service.chat(message, session_id)
except LLMError as e:
    # å¤„ç†LLMè°ƒç”¨é”™è¯¯
    logger.error(f"LLMé”™è¯¯: {e}")
    response = "æŠ±æ­‰,æˆ‘ç°åœ¨æ— æ³•å›å¤"
except (VectorStoreError, GraphStoreError) as e:
    # å¤„ç†å­˜å‚¨é”™è¯¯
    logger.error(f"å­˜å‚¨é”™è¯¯: {e}")
    response = "æŠ±æ­‰,æ•°æ®æ£€ç´¢å¤±è´¥"
```

### 6.5 æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **ç¼“å­˜ç­–ç•¥**: ä½¿ç”¨LLMç¼“å­˜å‡å°‘é‡å¤è°ƒç”¨
2. **æ‰¹é‡å¤„ç†**: å¯¹å¤šä¸ªè¯·æ±‚ä½¿ç”¨`batch_call`
3. **å¼‚æ­¥è°ƒç”¨**: å¯¹äºè€—æ—¶æ“ä½œä½¿ç”¨å¼‚æ­¥æ–¹å¼
4. **å‘é‡ç´¢å¼•ä¼˜åŒ–**: å®šæœŸé‡å»º Faiss ç´¢å¼•æå‡æ£€ç´¢æ•ˆç‡
5. **å›¾è°±æŸ¥è¯¢ä¼˜åŒ–**: ä½¿ç”¨ç´¢å¼•åŠ é€ŸCypheræŸ¥è¯¢

---


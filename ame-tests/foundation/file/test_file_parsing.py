"""
æ–‡æ¡£è§£ææ¨¡å—è„šæœ¬åŒ–æµ‹è¯•
"""

import sys
import asyncio
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent.parent.parent))

from ame.foundation.file import (
    DocumentParsePipeline,
    parse_document,
    DocumentFormat,
    SectionType,
)


def print_separator(title=""):
    """æ‰“å°åˆ†éš”çº¿"""
    if title:
        print(f"\n{'='*80}")
        print(f"  {title}")
        print(f"{'='*80}")
    else:
        print("-" * 80)


def print_section(section, indent=0):
    """æ‰“å°æ–‡æ¡£ç‰‡æ®µ"""
    prefix = "  " * indent
    print(f"{prefix}[{section.type.value}] {section.content[:100]}..." if len(section.content) > 100 else f"{prefix}[{section.type.value}] {section.content}")


async def test_file(file_path: str):
    """æµ‹è¯•å•ä¸ªæ–‡ä»¶çš„è§£æ"""
    print_separator(f"æµ‹è¯•æ–‡ä»¶: {Path(file_path).name}")
    
    try:
        # è§£ææ–‡æ¡£
        doc = await parse_document(file_path)
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"\nğŸ“„ æ–‡ä»¶æ ¼å¼: {doc.format.value}")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - æ€»å­—ç¬¦æ•°: {doc.total_chars}")
        print(f"   - æ€»å•è¯æ•°: {doc.total_words}")
        print(f"   - ç‰‡æ®µæ•°é‡: {len(doc.sections)}")
        
        # åŸå§‹å†…å®¹é¢„è§ˆ
        print(f"\nğŸ“ åŸå§‹å†…å®¹é¢„è§ˆ (å‰200å­—ç¬¦):")
        print(f"   {doc.raw_content[:200]}..." if len(doc.raw_content) > 200 else f"   {doc.raw_content}")
        
        # ç‰‡æ®µè¯¦æƒ…
        print(f"\nğŸ“‘ ç‰‡æ®µåˆ—è¡¨:")
        for i, section in enumerate(doc.sections[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
            print_section(section)
        
        if len(doc.sections) > 10:
            print(f"   ... è¿˜æœ‰ {len(doc.sections) - 10} ä¸ªç‰‡æ®µ")
        
        # æ ‡é¢˜å¤§çº²(å¦‚æœæœ‰)
        headings = doc.get_headings()
        if headings:
            print(f"\nğŸ—‚ï¸  æ–‡æ¡£å¤§çº²:")
            for heading in headings:
                indent = int(heading.type.value.split('_')[-1]) - 1 if 'HEADING' in heading.type.value else 0
                print(f"{'  ' * indent}- {heading.content}")
        
        # å­—å…¸æ ¼å¼
        print(f"\nğŸ“¦ å­—å…¸æ ¼å¼ (éƒ¨åˆ†):")
        doc_dict = doc.to_dict()
        print(f"   Keys: {list(doc_dict.keys())}")
        print(f"   Metadata: {doc_dict.get('metadata', {})}")
        
        print(f"\nâœ… è§£ææˆåŠŸ!")
        
    except Exception as e:
        print(f"\nâŒ è§£æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


async def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    # æµ‹è¯•æ–‡ä»¶ç›®å½•
    test_dir = Path(__file__).parent / "test_file"
    
    print_separator("æ–‡æ¡£è§£ææ¨¡å—è„šæœ¬åŒ–æµ‹è¯•")
    print(f"\næµ‹è¯•ç›®å½•: {test_dir}")
    
    # åˆ—å‡ºæ‰€æœ‰æµ‹è¯•æ–‡ä»¶
    test_files = sorted(test_dir.glob("*"))
    test_files = [f for f in test_files if f.is_file()]
    
    print(f"\nå‘ç° {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶:")
    for f in test_files:
        print(f"  - {f.name} ({f.suffix})")
    
    # æ˜¾ç¤ºæ”¯æŒçš„æ ¼å¼
    pipeline = DocumentParsePipeline()
    print(f"\næ”¯æŒçš„æ ¼å¼:")
    formats = pipeline.get_supported_formats()
    for parser, exts in formats.items():
        print(f"  - {parser}: {', '.join(exts)}")
    
    # æµ‹è¯•æ¯ä¸ªæ–‡ä»¶
    for file_path in test_files:
        if pipeline.is_supported(str(file_path)):
            await test_file(str(file_path))
        else:
            print_separator(f"è·³è¿‡ä¸æ”¯æŒçš„æ–‡ä»¶: {file_path.name}")
            print(f"   æ–‡ä»¶ç±»å‹: {file_path.suffix}")
    
    print_separator("æ‰€æœ‰æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    asyncio.run(main())
